{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data\n",
    "traindata = pd.read_csv(\"adult.data\", header=None, sep=', ')\n",
    "testdata = pd.read_csv(\"adult.test.txt\", header = None,  sep=', ')\n",
    "\n",
    "# add the column name\n",
    "testdata.columns = [\n",
    "    \"Age\", \"WorkClass\", \"fnlwgt\", \"Education\", \"EducationNum\",\n",
    "    \"MaritalStatus\", \"Occupation\", \"Relationship\", \"Race\", \"Gender\",\n",
    "    \"CapitalGain\", \"CapitalLoss\", \"HoursPerWeek\", \"NativeCountry\", \"Income\"\n",
    "]\n",
    "\n",
    "traindata.columns = [\n",
    "    \"Age\", \"WorkClass\", \"fnlwgt\", \"Education\", \"EducationNum\",\n",
    "    \"MaritalStatus\", \"Occupation\", \"Relationship\", \"Race\", \"Gender\",\n",
    "    \"CapitalGain\", \"CapitalLoss\", \"HoursPerWeek\", \"NativeCountry\", \"Income\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's convert the <=50Ks into 0 and the >50K into +1\n",
    "traindata[\"Income\"] = traindata[\"Income\"].map({ \"<=50K\": 0, \">50K\": 1 })\n",
    "testdata[\"Income\"] = testdata[\"Income\"].map({ \"<=50K.\": 0, \">50K.\": 1 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the missing values\n",
    "# train: 30162 row data; test 15060 row data\n",
    "for i in traindata.columns:\n",
    "    traindata = traindata[traindata[i] != '?'] \n",
    "    testdata = testdata[testdata[i] != '?'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"1-of-K\" encoding\n",
    "traindata = pd.get_dummies(traindata, columns=[\n",
    "    \"WorkClass\", \"Education\", \"MaritalStatus\", \"Occupation\", \"Relationship\",\"Race\", \"Gender\", \"NativeCountry\",])\n",
    "testdata = pd.get_dummies(testdata, columns=[\n",
    "    \"WorkClass\", \"Education\", \"MaritalStatus\", \"Occupation\", \"Relationship\",\"Race\", \"Gender\", \"NativeCountry\",])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the features which frequency < 11 of trainning data\n",
    "for i in traindata.columns:\n",
    "    total = traindata[i].sum()\n",
    "    if total < 11:\n",
    "        traindata = traindata.drop([i], axis=1)\n",
    "\n",
    "# drop the columns which are not in the traindata\n",
    "for i in testdata.columns:\n",
    "    if i not in traindata.columns:\n",
    "        testdata = testdata.drop([i], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (30162, 103) test: (15060, 103)\n"
     ]
    }
   ],
   "source": [
    "# check the shape of dataset\n",
    "print(\"train:\", traindata.shape, \"test:\", testdata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-organize the data\n",
    "x_train = traindata.drop(['Income'], axis=1)\n",
    "y_train = traindata['Income'] \n",
    "x_test = testdata.drop(['Income'], axis=1)\n",
    "y_test = testdata['Income'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Summary statistics of train data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Age        fnlwgt  EducationNum   CapitalGain   CapitalLoss  \\\n",
      "count  30162.000000  3.016200e+04  30162.000000  30162.000000  30162.000000   \n",
      "mean      38.437902  1.897938e+05     10.121312   1092.007858     88.372489   \n",
      "std       13.134665  1.056530e+05      2.549995   7406.346497    404.298370   \n",
      "min       17.000000  1.376900e+04      1.000000      0.000000      0.000000   \n",
      "25%       28.000000  1.176272e+05      9.000000      0.000000      0.000000   \n",
      "50%       37.000000  1.784250e+05     10.000000      0.000000      0.000000   \n",
      "75%       47.000000  2.376285e+05     13.000000      0.000000      0.000000   \n",
      "max       90.000000  1.484705e+06     16.000000  99999.000000   4356.000000   \n",
      "\n",
      "       HoursPerWeek  WorkClass_Federal-gov  WorkClass_Local-gov  \\\n",
      "count  30162.000000           30162.000000         30162.000000   \n",
      "mean      40.931238               0.031265             0.068530   \n",
      "std       11.979984               0.174035             0.252657   \n",
      "min        1.000000               0.000000             0.000000   \n",
      "25%       40.000000               0.000000             0.000000   \n",
      "50%       40.000000               0.000000             0.000000   \n",
      "75%       45.000000               0.000000             0.000000   \n",
      "max       99.000000               1.000000             1.000000   \n",
      "\n",
      "       WorkClass_Private  WorkClass_Self-emp-inc  ...  NativeCountry_Portugal  \\\n",
      "count       30162.000000            30162.000000  ...            30162.000000   \n",
      "mean            0.738877                0.035608  ...                0.001127   \n",
      "std             0.439254                0.185313  ...                0.033556   \n",
      "min             0.000000                0.000000  ...                0.000000   \n",
      "25%             0.000000                0.000000  ...                0.000000   \n",
      "50%             1.000000                0.000000  ...                0.000000   \n",
      "75%             1.000000                0.000000  ...                0.000000   \n",
      "max             1.000000                1.000000  ...                1.000000   \n",
      "\n",
      "       NativeCountry_Puerto-Rico  NativeCountry_Scotland  NativeCountry_South  \\\n",
      "count               30162.000000            30162.000000         30162.000000   \n",
      "mean                    0.003614                0.000365             0.002354   \n",
      "std                     0.060007                0.019094             0.048461   \n",
      "min                     0.000000                0.000000             0.000000   \n",
      "25%                     0.000000                0.000000             0.000000   \n",
      "50%                     0.000000                0.000000             0.000000   \n",
      "75%                     0.000000                0.000000             0.000000   \n",
      "max                     1.000000                1.000000             1.000000   \n",
      "\n",
      "       NativeCountry_Taiwan  NativeCountry_Thailand  \\\n",
      "count          30162.000000            30162.000000   \n",
      "mean               0.001392                0.000564   \n",
      "std                0.037291                0.023734   \n",
      "min                0.000000                0.000000   \n",
      "25%                0.000000                0.000000   \n",
      "50%                0.000000                0.000000   \n",
      "75%                0.000000                0.000000   \n",
      "max                1.000000                1.000000   \n",
      "\n",
      "       NativeCountry_Trinadad&Tobago  NativeCountry_United-States  \\\n",
      "count                   30162.000000                 30162.000000   \n",
      "mean                        0.000597                     0.911876   \n",
      "std                         0.024422                     0.283480   \n",
      "min                         0.000000                     0.000000   \n",
      "25%                         0.000000                     1.000000   \n",
      "50%                         0.000000                     1.000000   \n",
      "75%                         0.000000                     1.000000   \n",
      "max                         1.000000                     1.000000   \n",
      "\n",
      "       NativeCountry_Vietnam  NativeCountry_Yugoslavia  \n",
      "count           30162.000000              30162.000000  \n",
      "mean                0.002122                  0.000530  \n",
      "std                 0.046016                  0.023026  \n",
      "min                 0.000000                  0.000000  \n",
      "25%                 0.000000                  0.000000  \n",
      "50%                 0.000000                  0.000000  \n",
      "75%                 0.000000                  0.000000  \n",
      "max                 1.000000                  1.000000  \n",
      "\n",
      "[8 rows x 102 columns]\n",
      "\n",
      "Label counts:\n",
      "0    22654\n",
      "1     7508\n",
      "Name: Income, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(x_train.describe())\n",
    "print(\"\\nLabel counts:\")\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Summary statistics of test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Age        fnlwgt  EducationNum   CapitalGain   CapitalLoss  \\\n",
      "count  15060.000000  1.506000e+04  15060.000000  15060.000000  15060.000000   \n",
      "mean      38.768327  1.896164e+05     10.112749   1120.301594     89.041899   \n",
      "std       13.380676  1.056150e+05      2.558727   7703.181842    406.283245   \n",
      "min       17.000000  1.349200e+04      1.000000      0.000000      0.000000   \n",
      "25%       28.000000  1.166550e+05      9.000000      0.000000      0.000000   \n",
      "50%       37.000000  1.779550e+05     10.000000      0.000000      0.000000   \n",
      "75%       48.000000  2.385888e+05     13.000000      0.000000      0.000000   \n",
      "max       90.000000  1.490400e+06     16.000000  99999.000000   3770.000000   \n",
      "\n",
      "       HoursPerWeek  WorkClass_Federal-gov  WorkClass_Local-gov  \\\n",
      "count  15060.000000           15060.000000         15060.000000   \n",
      "mean      40.951594               0.030744             0.068592   \n",
      "std       12.062831               0.172628             0.252768   \n",
      "min        1.000000               0.000000             0.000000   \n",
      "25%       40.000000               0.000000             0.000000   \n",
      "50%       40.000000               0.000000             0.000000   \n",
      "75%       45.000000               0.000000             0.000000   \n",
      "max       99.000000               1.000000             1.000000   \n",
      "\n",
      "       WorkClass_Private  WorkClass_Self-emp-inc  ...  NativeCountry_Portugal  \\\n",
      "count       15060.000000            15060.000000  ...            15060.000000   \n",
      "mean            0.731806                0.037981  ...                0.001859   \n",
      "std             0.443034                0.191158  ...                0.043080   \n",
      "min             0.000000                0.000000  ...                0.000000   \n",
      "25%             0.000000                0.000000  ...                0.000000   \n",
      "50%             1.000000                0.000000  ...                0.000000   \n",
      "75%             1.000000                0.000000  ...                0.000000   \n",
      "max             1.000000                1.000000  ...                1.000000   \n",
      "\n",
      "       NativeCountry_Puerto-Rico  NativeCountry_Scotland  NativeCountry_South  \\\n",
      "count               15060.000000            15060.000000         15060.000000   \n",
      "mean                    0.004382                0.000598             0.001992   \n",
      "std                     0.066057                0.024440             0.044589   \n",
      "min                     0.000000                0.000000             0.000000   \n",
      "25%                     0.000000                0.000000             0.000000   \n",
      "50%                     0.000000                0.000000             0.000000   \n",
      "75%                     0.000000                0.000000             0.000000   \n",
      "max                     1.000000                1.000000             1.000000   \n",
      "\n",
      "       NativeCountry_Taiwan  NativeCountry_Thailand  \\\n",
      "count          15060.000000            15060.000000   \n",
      "mean               0.000863                0.000797   \n",
      "std                0.029369                0.028218   \n",
      "min                0.000000                0.000000   \n",
      "25%                0.000000                0.000000   \n",
      "50%                0.000000                0.000000   \n",
      "75%                0.000000                0.000000   \n",
      "max                1.000000                1.000000   \n",
      "\n",
      "       NativeCountry_Trinadad&Tobago  NativeCountry_United-States  \\\n",
      "count                   15060.000000                 15060.000000   \n",
      "mean                        0.000531                     0.915538   \n",
      "std                         0.023043                     0.278089   \n",
      "min                         0.000000                     0.000000   \n",
      "25%                         0.000000                     1.000000   \n",
      "50%                         0.000000                     1.000000   \n",
      "75%                         0.000000                     1.000000   \n",
      "max                         1.000000                     1.000000   \n",
      "\n",
      "       NativeCountry_Vietnam  NativeCountry_Yugoslavia  \n",
      "count           15060.000000              15060.000000  \n",
      "mean                0.001262                  0.000465  \n",
      "std                 0.035498                  0.021555  \n",
      "min                 0.000000                  0.000000  \n",
      "25%                 0.000000                  0.000000  \n",
      "50%                 0.000000                  0.000000  \n",
      "75%                 0.000000                  0.000000  \n",
      "max                 1.000000                  1.000000  \n",
      "\n",
      "[8 rows x 102 columns]\n",
      "\n",
      "Label counts:\n",
      "0    11360\n",
      "1     3700\n",
      "Name: Income, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(x_test.describe())\n",
    "print(\"\\nLabel counts:\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以本題求的error function為例，可以導出gradient 與hessian 如下：\n",
    "1. gradient() <br>\n",
    "lambda_matrix: 對角矩陣的lambda值 <br>\n",
    "w: coefficient of features <br>\n",
    "x_train: trainning data of features <br>\n",
    "y_train: trainning data of labels <br>\n",
    "p: sigmoid 轉換後得出之機率 <br>\n",
    "<br>\n",
    "2. hessian() <br>\n",
    "lambda_matrix: 對角矩陣的lambda值 <br>\n",
    "w: coefficient of features <br>\n",
    "x_train: trainning data of features <br>\n",
    "p: sigmoid 轉換後得出之機率 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(lambda_matrix, w, x_train, y_train, p):\n",
    "    g = lambda_matrix @ w + x_train @ (p - y_train)   \n",
    "    \n",
    "    return g\n",
    "\n",
    "def hessian(lambda_matrix, w, x_train, p):\n",
    "    H = lambda_matrix @ np.identity(lambda_matrix.shape[0]) + x_train.T @ np.diag(mat(p*(1-p)).getA1()) @ x_train  \n",
    "    \n",
    "    return H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mylogistic_l2():\n",
    "    \n",
    "    def __init__(self, reg_vec, max_iter, tol, add_intercept):\n",
    "        self.reg_vec = reg_vec\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.add_intercept = add_intercept\n",
    "        return\n",
    "        \n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        p_matrix = 1.0/(1.0+exp(-x))\n",
    "        p_array = np.squeeze(p_matrix)\n",
    "        p_array[p_array > 0.99] = 0.999999\n",
    "        p_array[p_array <= 0] = 0.000001\n",
    "\n",
    "        p_matrix2 = p_array.reshape(p_matrix.shape[0], p_matrix.shape[1])\n",
    "\n",
    "        return p_matrix2\n",
    "\n",
    "    def fit(self, x_train , y_train):\n",
    "        self.x_train = x_train.copy()\n",
    "        self.y_train = y_train.copy()\n",
    "        \n",
    "        samples, features = self.x_train.shape\n",
    "        \n",
    "        \n",
    "        # check if need intercept then features would puls 1\n",
    "        if self.add_intercept == True:\n",
    "            self.x_train = np.hstack((self.x_train, np.ones((self.x_train.shape[0],1))))\n",
    "\n",
    "            \n",
    "        self.y_train = self.y_train.reshape(samples,1)\n",
    "\n",
    "        # create lambda diagnoal marix\n",
    "        lambda_matrix = np.diag(self.reg_vec)\n",
    "\n",
    "\n",
    "        # use closed form sol of ridge regression as initail value of coefficient vector: w\n",
    "        b = np.mean(self.reg_vec)\n",
    "        self.w = np.linalg.inv(self.x_train.T @ self.x_train + b * np.identity(1)) @ self.x_train.T @ self.y_train\n",
    "\n",
    "        # other initial values\n",
    "        iternum = 0 \n",
    "        loss0 = float('inf')\n",
    "        \n",
    "        while iternum < self.max_iter:\n",
    "                p = self.sigmoid(self.x_train @ self.w) # MLE\n",
    "                \n",
    "                g = lambda_matrix @ self.w + self.x_train.T @ (p - self.y_train)   # gradient\n",
    "                # hessian\n",
    "                H = lambda_matrix @ np.identity(lambda_matrix.shape[0]) + self.x_train.T @ np.diag(mat(p*(1-p)).getA1()) @ self.x_train  \n",
    "\n",
    "                loss = (self.w.T @ lambda_matrix @ self.w) - sum(self.y_train.T @ np.log(p) + (1 - self.y_train).T @ np.log(1-p)) \n",
    "\n",
    "                self.w = self.w -  np.linalg.inv(H) @ g  # update w\n",
    "                iternum += 1\n",
    "               \n",
    "                \n",
    "                if loss0 - loss < self.tol:\n",
    "                    break\n",
    "                    \n",
    "                loss0 = loss\n",
    "                \n",
    "                print(iternum, loss0, loss, loss0-loss)\n",
    "                                \n",
    "        return self.w\n",
    "\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        \n",
    "        if self.add_intercept == True:\n",
    "            x_test = np.hstack((x_test, np.ones((x_test.shape[0],1)))) \n",
    "            \n",
    "        y_pred = []\n",
    "        y_array = np.squeeze(self.sigmoid(x_test @ self.w))\n",
    "\n",
    "        for i in range(len(y_array)):\n",
    "            if i >= 0.5:\n",
    "                tmp = 1\n",
    "                y_pred.append(tmp)\n",
    "            else:\n",
    "                tmp = 0\n",
    "                y_pred.append(tmp)\n",
    "        \n",
    "        return y_pred\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dataset to array type\n",
    "x_train = np.asarray(x_train)\n",
    "y_train = np.asarray(y_train)\n",
    "x_test = np.asarray(x_test)\n",
    "y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 102 features, including: <br>\n",
    "5 continuous variables <br>\n",
    "97 binary variables <br>\n",
    "\n",
    "if intercept is true <br>\n",
    "then we have another feature as last column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### case1: lambda = 1 for all coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [[2.05921178e+31]] [[2.05921178e+31]] [[0.]]\n",
      "2 [[843796.78073062]] [[843796.78073062]] [[0.]]\n"
     ]
    }
   ],
   "source": [
    "# run the model\n",
    "lambda_vec = [1 for i in range(103)]\n",
    "reg = mylogistic_l2(reg_vec = lambda_vec, max_iter = 1000, tol =0.00001, add_intercept = True)\n",
    "w = reg.fit(x_train, y_train)\n",
    "y_pred = reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.24575033200531207\n",
      "Learned w: \n",
      " [[-1.11521617e+03]\n",
      " [ 9.25781811e-02]\n",
      " [ 1.19705998e+03]\n",
      " [ 4.48993005e-01]\n",
      " [ 1.60385820e+00]\n",
      " [ 2.26250477e+02]\n",
      " [ 8.98976911e+02]\n",
      " [-1.46984449e+03]\n",
      " [ 3.02227114e+03]\n",
      " [-6.87619374e+02]\n",
      " [-1.63733094e+03]\n",
      " [-1.27715808e+03]\n",
      " [-9.64858917e+00]\n",
      " [-5.31474510e+02]\n",
      " [-4.01641983e+02]\n",
      " [-2.77684192e+02]\n",
      " [-1.03293798e+02]\n",
      " [-2.07288276e+02]\n",
      " [-9.43697251e+02]\n",
      " [-4.21844301e+02]\n",
      " [ 3.37215987e+02]\n",
      " [ 3.26704062e+03]\n",
      " [ 2.41273650e+03]\n",
      " [-1.27281699e+01]\n",
      " [ 7.27826896e+02]\n",
      " [-2.89221460e+03]\n",
      " [-3.02250327e+01]\n",
      " [-4.26049174e+01]\n",
      " [-2.04047639e+03]\n",
      " [ 3.02585448e+02]\n",
      " [-1.05976321e+00]\n",
      " [ 6.10058972e+02]\n",
      " [-2.63398254e+02]\n",
      " [-3.38692566e+03]\n",
      " [ 2.28089217e+03]\n",
      " [-7.02506336e+02]\n",
      " [ 1.21373472e+03]\n",
      " [ 2.24104756e+02]\n",
      " [-8.79423962e+02]\n",
      " [-1.00489409e+03]\n",
      " [-9.32748398e+02]\n",
      " [-3.52298882e+02]\n",
      " [ 4.75914310e+01]\n",
      " [-9.77109933e+01]\n",
      " [ 1.33695861e+03]\n",
      " [-2.92748877e+02]\n",
      " [-7.51235356e+01]\n",
      " [ 7.16113533e+02]\n",
      " [-1.06285470e+03]\n",
      " [ 1.99664435e+03]\n",
      " [ 3.26409234e+02]\n",
      " [-2.73308255e+02]\n",
      " [ 3.11551625e+02]\n",
      " [-2.17153531e+03]\n",
      " [-1.35011506e+03]\n",
      " [ 4.90534928e+02]\n",
      " [-6.87314195e+01]\n",
      " [-1.31327711e+02]\n",
      " [-4.84357674e+01]\n",
      " [-1.40239345e+03]\n",
      " [-5.99146216e+02]\n",
      " [-5.61207203e+02]\n",
      " [ 4.96088342e-02]\n",
      " [-2.61721565e+01]\n",
      " [-1.25919042e+01]\n",
      " [-2.37981229e+01]\n",
      " [ 4.57083475e+01]\n",
      " [-3.75080096e+01]\n",
      " [-9.19978068e+02]\n",
      " [-3.79583009e+01]\n",
      " [-1.94057076e+01]\n",
      " [-1.41573299e+00]\n",
      " [-1.68650935e+01]\n",
      " [-1.24976745e+01]\n",
      " [-2.51442010e+01]\n",
      " [-4.95066036e+02]\n",
      " [-5.00129551e+00]\n",
      " [ 1.82438067e+00]\n",
      " [-5.75639227e+00]\n",
      " [-4.03153225e+00]\n",
      " [-8.99175321e-01]\n",
      " [ 6.10804961e+02]\n",
      " [-2.38885755e+01]\n",
      " [-1.90623110e+01]\n",
      " [ 5.90319688e+00]\n",
      " [-2.04047016e+00]\n",
      " [-1.91831575e+02]\n",
      " [-7.26947108e+00]\n",
      " [-6.92020727e+00]\n",
      " [-8.14189322e+00]\n",
      " [-3.39190355e+00]\n",
      " [-2.05307570e+01]\n",
      " [-1.85205919e+01]\n",
      " [-4.81101990e+01]\n",
      " [-5.91730379e+00]\n",
      " [-1.27186788e+01]\n",
      " [ 3.82127675e+00]\n",
      " [-2.00868855e+00]\n",
      " [-1.07664486e+01]\n",
      " [ 2.07706448e+02]\n",
      " [-1.09841267e+01]\n",
      " [ 1.00490769e+00]\n",
      " [-1.16035342e+03]]\n"
     ]
    }
   ],
   "source": [
    "#Accuracy\n",
    "hit = 0.\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i]== y_test[i]:\n",
    "        hit += 1\n",
    "        \n",
    "print(\"Accuracy:\", hit/x_test.shape[0])\n",
    "print(\"Learned w: \\n\", w) # the last item is intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 2: lambda = 1 for all but the intercept, no regularization for incercept term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [[1.719186e+30]] [[1.719186e+30]] [[0.]]\n",
      "2 [[3374356.542807]] [[3374356.542807]] [[0.]]\n"
     ]
    }
   ],
   "source": [
    "# run the model\n",
    "lambda_vec = [1 for i in range(102)] + [0]\n",
    "reg = mylogistic_l2(reg_vec = lambda_vec, max_iter = 1000, tol =0.00001, add_intercept = True)\n",
    "w = reg.fit(x_train, y_train)\n",
    "y_pred = reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.24575033200531207\n",
      "Learned w: \n",
      " [[ 2.77606250e+04]\n",
      " [ 4.90404421e-01]\n",
      " [-1.57204563e+03]\n",
      " [ 5.69618969e+00]\n",
      " [ 2.25983130e+01]\n",
      " [ 5.94029420e+03]\n",
      " [-5.56430942e+01]\n",
      " [-4.06705084e+02]\n",
      " [ 1.19563692e+03]\n",
      " [-3.57548749e+01]\n",
      " [-4.81780369e+02]\n",
      " [-2.11851585e+02]\n",
      " [-3.90191212e+00]\n",
      " [-6.68553722e+01]\n",
      " [-7.12399544e+01]\n",
      " [-3.87501783e+01]\n",
      " [-2.74842374e+00]\n",
      " [-9.60389219e+00]\n",
      " [-6.97440757e+01]\n",
      " [-3.30561046e+01]\n",
      " [-2.26327865e+02]\n",
      " [-2.15207288e+02]\n",
      " [-5.65982887e+02]\n",
      " [-2.23282815e+01]\n",
      " [-5.19500071e+02]\n",
      " [-1.94799931e+02]\n",
      " [ 1.74793654e+00]\n",
      " [-5.68690065e+00]\n",
      " [ 2.04008329e+03]\n",
      " [-1.26844352e+03]\n",
      " [ 2.82246659e+00]\n",
      " [ 9.55604373e+02]\n",
      " [ 2.27793877e+03]\n",
      " [-1.43843697e+03]\n",
      " [-2.75450382e+02]\n",
      " [-2.54034734e+02]\n",
      " [-6.98868272e+02]\n",
      " [-4.77934064e+02]\n",
      " [-1.52430627e+02]\n",
      " [-2.38217231e+02]\n",
      " [-2.28402085e+02]\n",
      " [-3.01585410e+02]\n",
      " [-5.61899108e+02]\n",
      " [-2.75830982e+01]\n",
      " [-4.16092860e+02]\n",
      " [-7.64603719e+01]\n",
      " [ 3.47444912e+03]\n",
      " [-7.22710764e+01]\n",
      " [-2.20009051e+02]\n",
      " [ 8.29245199e+02]\n",
      " [-1.55643963e+03]\n",
      " [-1.73935972e+02]\n",
      " [-6.29611395e+02]\n",
      " [ 1.37333595e+03]\n",
      " [ 1.57405841e+02]\n",
      " [-4.93771882e+01]\n",
      " [-9.35925741e+01]\n",
      " [-6.23676196e+02]\n",
      " [-4.20500773e+01]\n",
      " [ 8.08696036e+02]\n",
      " [ 8.97097809e+02]\n",
      " [-8.97097809e+02]\n",
      " [ 2.20486604e+00]\n",
      " [-4.20230919e+00]\n",
      " [-7.00039381e+00]\n",
      " [-1.59098218e+01]\n",
      " [-1.44691925e+01]\n",
      " [-1.33756984e+01]\n",
      " [-5.48998258e+00]\n",
      " [-8.51694394e+00]\n",
      " [-9.88811486e+00]\n",
      " [-2.41015816e+00]\n",
      " [-9.57773638e+00]\n",
      " [-9.78538483e-01]\n",
      " [-5.46925746e+00]\n",
      " [-6.29897524e+00]\n",
      " [-2.73806552e+00]\n",
      " [-1.69331557e+00]\n",
      " [-6.96485733e-01]\n",
      " [-1.17229660e+01]\n",
      " [-4.78892434e+00]\n",
      " [-2.29955222e+00]\n",
      " [-5.37628410e+00]\n",
      " [-1.37414359e+01]\n",
      " [-8.11253889e+00]\n",
      " [-2.35736604e+00]\n",
      " [-7.89367865e+01]\n",
      " [-8.36814588e+00]\n",
      " [-3.56700747e+00]\n",
      " [-5.04701385e+00]\n",
      " [-1.92517734e+01]\n",
      " [-7.78112085e+00]\n",
      " [-2.14495976e+00]\n",
      " [-1.73616296e+01]\n",
      " [-2.25851052e+00]\n",
      " [-1.40583160e+01]\n",
      " [-1.38729893e+00]\n",
      " [-4.24364301e+00]\n",
      " [-3.50859248e+00]\n",
      " [ 3.34625113e+02]\n",
      " [-9.95930586e+00]\n",
      " [-1.39715269e+00]\n",
      " [-1.69906245e+06]]\n"
     ]
    }
   ],
   "source": [
    "#Accuracy\n",
    "hit = 0.\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i]== y_test[i]:\n",
    "        hit += 1\n",
    "        \n",
    "print(\"Accuracy:\", hit/x_test.shape[0])\n",
    "print(\"Learned w: \\n\", w) # the last item is intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 3: lambda = 1 for numerical-valued features, lambda = 0.5 for binary-valued features, no regularization for incercept term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [[6.82245248e+31]] [[6.82245248e+31]] [[0.]]\n",
      "2 [[2.37264683e+08]] [[2.37264683e+08]] [[0.]]\n"
     ]
    }
   ],
   "source": [
    "# run the model\n",
    "lambda_vec = [1 for i in range(5)] + [0.5 for i in range(97)] + [0]\n",
    "reg = mylogistic_l2(reg_vec = lambda_vec, max_iter = 1000, tol =0.00001, add_intercept = True)\n",
    "w = reg.fit(x_train, y_train)\n",
    "y_pred = reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.24575033200531207\n",
      "Learned w: \n",
      " [[-3.54992966e+02]\n",
      " [ 3.33441803e-01]\n",
      " [ 7.51519586e+03]\n",
      " [ 1.78865254e+01]\n",
      " [ 1.49939006e+02]\n",
      " [ 3.70344233e+03]\n",
      " [ 1.98140025e+02]\n",
      " [ 1.05897283e+02]\n",
      " [-4.90314510e+02]\n",
      " [ 3.88672572e+02]\n",
      " [-1.68301017e+02]\n",
      " [-2.56978253e+01]\n",
      " [-8.39652847e+00]\n",
      " [-3.84600272e+02]\n",
      " [-5.08120349e+02]\n",
      " [ 2.03244241e+03]\n",
      " [-1.09353673e+02]\n",
      " [-1.71373950e+02]\n",
      " [-3.49022622e+02]\n",
      " [-2.11660055e+02]\n",
      " [-2.85289616e+01]\n",
      " [ 8.96214058e+01]\n",
      " [ 9.42851928e+02]\n",
      " [ 2.60656703e+02]\n",
      " [-1.49776992e+03]\n",
      " [ 7.86125550e+02]\n",
      " [-3.40310026e+01]\n",
      " [ 2.86404143e+02]\n",
      " [-1.10364133e+03]\n",
      " [-1.11424729e+03]\n",
      " [ 7.96122189e+00]\n",
      " [ 4.51380529e+03]\n",
      " [-1.21345530e+02]\n",
      " [-2.52680727e+03]\n",
      " [-2.92184693e+02]\n",
      " [-4.67181720e+02]\n",
      " [-9.39939051e+02]\n",
      " [-1.88330423e+02]\n",
      " [ 1.31603935e+03]\n",
      " [-3.96435125e+02]\n",
      " [-5.20579210e+02]\n",
      " [-4.01622873e+02]\n",
      " [ 6.84826132e+02]\n",
      " [-9.12288601e+01]\n",
      " [ 9.86003334e+02]\n",
      " [ 8.73578821e+01]\n",
      " [-3.39120331e+02]\n",
      " [ 5.54166159e+01]\n",
      " [-2.50840791e+02]\n",
      " [ 3.87052121e+03]\n",
      " [-2.59636176e+03]\n",
      " [-3.63466597e+02]\n",
      " [-5.98153182e+02]\n",
      " [-9.91801252e+02]\n",
      " [ 6.79261578e+02]\n",
      " [-7.13755177e+01]\n",
      " [-5.36914325e+01]\n",
      " [-7.25291613e+02]\n",
      " [-7.27873272e+01]\n",
      " [ 9.23145890e+02]\n",
      " [-3.21659237e+03]\n",
      " [ 3.21659237e+03]\n",
      " [ 4.22446194e+00]\n",
      " [-1.07168941e+01]\n",
      " [ 8.40116123e-01]\n",
      " [-2.56198874e+01]\n",
      " [-8.44721653e+00]\n",
      " [-2.96265092e+01]\n",
      " [-3.65331526e+00]\n",
      " [-2.88030324e+01]\n",
      " [ 8.65690115e+00]\n",
      " [ 1.15402143e+01]\n",
      " [ 1.76259696e+01]\n",
      " [-6.82361376e+00]\n",
      " [-2.40622121e+01]\n",
      " [-1.50167900e+01]\n",
      " [-1.89053686e+00]\n",
      " [ 6.38179927e-01]\n",
      " [-2.57141990e+00]\n",
      " [ 6.49716584e+00]\n",
      " [ 1.22021211e+01]\n",
      " [ 2.83850765e+00]\n",
      " [ 6.39420039e-01]\n",
      " [-1.10120710e+01]\n",
      " [ 1.38355623e+01]\n",
      " [-4.27129969e-01]\n",
      " [-2.53798304e+02]\n",
      " [-1.20617512e+01]\n",
      " [-6.14976714e+00]\n",
      " [-1.29905139e+01]\n",
      " [ 1.07934911e+01]\n",
      " [-2.70491105e+00]\n",
      " [-8.11273637e+00]\n",
      " [-2.90507100e+01]\n",
      " [-4.59060575e-01]\n",
      " [-1.78153098e+01]\n",
      " [ 3.38679689e+00]\n",
      " [-5.36249342e+00]\n",
      " [-3.81452303e+00]\n",
      " [ 4.48878435e+02]\n",
      " [-2.30333627e+01]\n",
      " [ 3.65849189e+00]\n",
      " [-3.88352934e+05]]\n"
     ]
    }
   ],
   "source": [
    "#Accuracy\n",
    "hit = 0.\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i]== y_test[i]:\n",
    "        hit += 1\n",
    "        \n",
    "print(\"Accuracy:\", hit/x_test.shape[0])\n",
    "print(\"Learned w: \\n\", w) # the last item is intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0.01\n",
    "step = 10\n",
    "a1 = 0.01\n",
    "a2 = 0.01\n",
    "\n",
    "while a1 < 100:\n",
    "    while a2 < 100:\n",
    "        # run the model\n",
    "lambda_vec = [1 for i in range(5)] + [0.5 for i in range(97)] + [0]\n",
    "reg = mylogistic_l2(reg_vec = lambda_vec, max_iter = 1000, tol =0.00001, add_intercept = True)\n",
    "w = reg.fit(x_train, y_train)\n",
    "y_pred = reg.predict(x_test)\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
